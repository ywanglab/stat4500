<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.398">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ch2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="ch2_files/libs/clipboard/clipboard.min.js"></script>
<script src="ch2_files/libs/quarto-html/quarto.js"></script>
<script src="ch2_files/libs/quarto-html/popper.min.js"></script>
<script src="ch2_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="ch2_files/libs/quarto-html/anchor.min.js"></script>
<link href="ch2_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ch2_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="ch2_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="ch2_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="ch2_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="chapter-2-statistical-learning" class="level1">
<h1>Chapter 2: Statistical Learning</h1>
<section id="what-is-statistical-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-is-statistical-learning">What is statistical learning?</h2>
<p>For the input variable <span class="math inline">\(X\in \mathbb{R}^p\)</span> and response variable <span class="math inline">\(Y\in \mathbb{R}\)</span>, assume that <span class="math display">\[Y=f(X) + \epsilon, \]</span> where <span class="math inline">\(\epsilon\)</span> is the random variable representing <strong>irreducible error</strong>. We assume <span class="math inline">\(\epsilon\)</span> is <em>independent</em> of <span class="math inline">\(X\)</span> and <span class="math inline">\(E[x]=0\)</span>. <span class="math inline">\(\epsilon\)</span> may include <em>unmeasured variables</em> or <em>unmeasurable variation</em>.</p>
<p>Statistical learning is to estimate <span class="math inline">\(f\)</span> using various methods. Denote the estimate by <span class="math inline">\(\hat{f}\)</span>.</p>
<ul>
<li>regression problem: when <span class="math inline">\(Y\)</span> is a continuous variable (quantitative). In this case <span class="math inline">\(f(x)=E(Y|X=x)\)</span> is the <em>regression</em> function, that is, regression finds a conditional expectation of <span class="math inline">\(Y\)</span>.</li>
<li>classification problem: when <span class="math inline">\(Y\)</span> only takes small number of discrete values, i.e., qualitative (categorical).</li>
</ul>
<p><strong>Logistic regression</strong> is a classification problem, but since it estimates class probability, it may be considered as a regression problem.</p>
<ul>
<li>supervised learning: training data <span class="math inline">\(\mathcal{Tr}=\{(x_i, y_i):i\in \mathbb{Z}_n\}\)</span>: linear regression, logistic regression</li>
<li>unsupervised learning: when only <span class="math inline">\(x_i\)</span> are available. clustering analysis, PCA</li>
<li>semi-supervised learning: some data with labels (<span class="math inline">\(y_i\)</span>), some do not.</li>
<li>reinforcement learning: learn a state-action policy function for an agent to interacting with an environment.</li>
</ul>
</section>
<section id="why-estimate-f" class="level2">
<h2 class="anchored" data-anchor-id="why-estimate-f">Why estimate <span class="math inline">\(f\)</span>?</h2>
<p>We can use estimated <span class="math inline">\(\hat{f}\)</span> to</p>
<ul>
<li>make predictions for a new <span class="math inline">\(X\)</span>, <span class="math display">\[\hat{Y} =\hat{f}(X). \]</span> The prediction error may be quantified as <span class="math display">\[E[(Y-\hat{Y})^2] = (f(X)-\hat{f})^2 +\text{Var}[\epsilon].\]</span> The first term of the error is <em>reducible</em> by trying to improve <span class="math inline">\(\hat{f}\)</span>, where we assume <span class="math inline">\(f\)</span>, <span class="math inline">\(\hat{f}\)</span> and <span class="math inline">\(X\)</span> are fixed.</li>
<li>make inference:
<ul>
<li>Which predictors are associated with the response?</li>
<li>which is the relationship between the response and each predictor?</li>
<li>is the assumed relationship adequate? (linear or more complicated?)</li>
</ul></li>
</ul>
</section>
<section id="how-to-estimate-f" class="level2">
<h2 class="anchored" data-anchor-id="how-to-estimate-f">How to estimate <span class="math inline">\(f\)</span></h2>
<p>We use obtained observations called <strong>training data</strong> <span class="math inline">\(\{(x_k, y_k): k \in \mathbb{Z}_n \}\)</span> to train an algorithm to obtain the estimate <span class="math inline">\(\hat{f}\)</span>.</p>
<ul>
<li><p>Parametric methods: first assume there is a function form (shape) with some parameters. For example, a linear regression model with two parameters. Then use the <em>training data</em> to <strong>train</strong> or <strong>fit</strong> the model to determine the values of the parameters.</p>
<p><strong>Advantages</strong>: simplify the problem of fit an arbitrary function to estimate a set of parameters.</p>
<p><strong>Disadvantages</strong>: may not be flexible unless with large number of parameters and/or complex function shapes.</p>
<p>Example: linear regression,</p></li>
<li><p>Non-parametric methods: Do not explicitly assume a function form of <span class="math inline">\(f\)</span>. They seek to estimate <span class="math inline">\(f\)</span> directly using data points, can be quite flexible and accurate.</p>
<p>**Disadvantage: need large number of data points</p>
<p>Example: KNN (breakdown for higher dimention. Typically only for <span class="math inline">\(p\le 4\)</span>), spline fit.</p></li>
</ul>
</section>
<section id="how-to-assess-model-accuracy" class="level2">
<h2 class="anchored" data-anchor-id="how-to-assess-model-accuracy">How to assess model accuracy</h2>
<p>For repression problems, the most commonly used measure is the <em>mean squared error</em> (MSE), given by <span class="math display">\[
MSE = \frac{1}{n}\sum_{i=1}^n (y_i-\hat{f}(x_i))^2
\]</span> For classification problems, typically the following <strong>error rate</strong> (classifications error) is calculated: <span class="math display">\[
\frac{1}{n} \sum_{i=1}^{n} I(y_i\ne \hat{y}_i)
\]</span> The accuracy on a training set can be arbitrarily increased by increasing the model flexibility. Since we are in general interested in the error on the test set rather on the training set, the model accuracy should be assessed on a test set.</p>
<p>Flexible models tend to overfit the data, which essentially means they follow the error or <em>noise</em> too closely in the training set, therefore cannot be generalized to <em>unseen cases</em> (test set).</p>
</section>
<section id="model-selection" class="level2">
<h2 class="anchored" data-anchor-id="model-selection">Model Selection:</h2>
<p><strong>No free lunch theorem</strong></p>
<p>There is no single best method for all data sets, which means some method works better than other methods for a particular dataset. Therefore, one needs to perform model selections. Here are some principles.</p>
<section id="trade-off-between-model-flexibility-and-model-interpretability" class="level3">
<h3 class="anchored" data-anchor-id="trade-off-between-model-flexibility-and-model-interpretability">Trade-off between Model flexibility and Model Interpretability</h3>
<p>More flexible models have higher <em>degree of freedom</em> and are less interpretable because it’s difficult to interpret the relationship between a predictor and the response.</p>
<p>LASSO is less flexible than linear regression. GAM allows some non-linearity. Full non-linear models have higher flexibility, such as <em>bagging, boosting, SVM</em>, etc.</p>
<p>When <em>inference</em> is the goal, then there are advantages to using simple and less flexible models for interpretability.</p>
<p>When <em>prediction</em> is the main goal, more flexible model may be a choice. But sometimes, we obtain more accurate prediction using a simpler model because the underlying dataset has a simpler structure. Therefore, it is not necessarily true that a more flexible model has a higher prediction accuracy.</p>
<p><strong>Occam’s Razor</strong>: Among competing hypotheses that perform equally well, the one with the fewest assumptions should be selected.</p>
</section>
<section id="model-selection-the-bias-variance-trade-off" class="level3">
<h3 class="anchored" data-anchor-id="model-selection-the-bias-variance-trade-off">Model Selection: the Bias-Variance Trade-off</h3>
<p>As the model flexibility increases, the training MSE (or error rate for classificiton) will decrease, but the test MSE (error rate) in general will not and will show a characteristic <strong>U-shape</strong>. This is because when evaluated at a test point <span class="math inline">\(x_0\)</span>, the expected test MSE can be decomposed into <span class="math display">\[
E\left[ (y_0-\hat{f}(x_0))^2 \right] = \text{Var}[\hat{f}(x_0)] + (\text{Bias}(\hat{f}(x_0)))^2+\text{Var}[\epsilon]
\]</span> where the expectation is over different <span class="math inline">\(\hat{f}\)</span> on a different training set or on a different training step if the training process is stochastic, and <span class="math display">\[
\text{Bias}(\hat{f}(x_0))= E[\hat{f}(x_0)]-f(x_0)
\]</span> To obtain the least test MSE, one must trade off between variance and bias. Less flexible model tendes to have higher bias, and more flexible models tend to have higher variance. An optimal flexibility for the least test MSE varies with different data sets. Non-linear data tends to require higher optimal flexibility.</p>
</section>
</section>
<section id="bayes-classifier" class="level2">
<h2 class="anchored" data-anchor-id="bayes-classifier">Bayes Classifier</h2>
<p>It can be shown that Bayes Classifier minimizes the classification test error <span class="math display">\[
\text{Ave}(I(y_0\ne \hat{y}_0)).
\]</span> A Bayes Classifier assigns a test observation with predictor <span class="math inline">\(x_0\)</span> to the class for which <span class="math display">\[
\text{Pr}(Y=j|X=x_0)
\]</span> is largest. It’s error rate is given by <span class="math display">\[
1-E[\max_{j} \text{Pr}(Y=j|X)]
\]</span></p>
<p>where the expectation is over <span class="math inline">\(X\)</span>. The Bayes error is analogous to the irreducible error <span class="math inline">\(\epsilon\)</span>.</p>
<p>Bayes Classifier is not attainable as we do not know <span class="math inline">\(\text{Pr}(Y|X)\)</span>. We only can estimate <span class="math inline">\(\text{Pr}(Y|X)\)</span>. One way to do this is by KNN. KNN estimate the conditional probability simply with a majority vote. The flexibility of KNN increases as <span class="math inline">\(1/K\)</span> increases with <span class="math inline">\(K=1\)</span> being the most flexible KNN. The training error is 0 for <span class="math inline">\(K=1\)</span>. A suitable <span class="math inline">\(K\)</span> should be chosen for an appropriate trade off between bias and variance. The KNN classifier will classify the test point <span class="math inline">\(x_0\)</span> based on the probability calculated from the <span class="math inline">\(k\)</span> nearest points. KNN regression on the other hand will assign the test point <span class="math inline">\(x_0\)</span> the average value of the <span class="math inline">\(k\)</span> nearest neighbors.</p>
</section>
<section id="homework-indicates-optional" class="level2">
<h2 class="anchored" data-anchor-id="homework-indicates-optional">Homework (* indicates optional):</h2>
<ul>
<li>Conceptual: 1,2,3,4*,5,6,7</li>
<li>Applied: 8, 9*, 10*</li>
</ul>
</section>
<section id="code-gist" class="level2">
<h2 class="anchored" data-anchor-id="code-gist">Code Gist</h2>
<section id="os" class="level3">
<h3 class="anchored" data-anchor-id="os">OS</h3>
<pre><code>import os
os.chdir(path) # change dir</code></pre>
</section>
<section id="python" class="level3">
<h3 class="anchored" data-anchor-id="python">Python:</h3>
<p>Concatenation using <code>+</code></p>
<pre><code>"hello" + " " + "world"  # 'hello world'
[3,4,5] + [4,9,7] # [3,4,5, 4,9,7]
</code></pre>
<p>String formatting</p>
<pre><code>print('Total is: {0}'.format(total))
</code></pre>
<p><code>zip</code> to loop over a sequence of tuples</p>
<pre><code>for value, weight in zip([2,3,19],
                         [0.2,0.3,0.5]):
    total += weight * value
</code></pre>
</section>
<section id="numpy" class="level3">
<h3 class="anchored" data-anchor-id="numpy">Numpy</h3>
<section id="numpy-functions" class="level4">
<h4 class="anchored" data-anchor-id="numpy-functions">Numpy functions:</h4>
<p><code>np.sum(x)</code>, <code>np.sqrt(x)</code> (entry wise). <code>x**2</code> (entry wise power), <code>np.corrcoef(x,y)</code> (find the correlation coefficient of array <code>x</code> and array <code>y</code>)</p>
<p><code>np.mean(axis=None)</code>: axis could be <code>None</code> (all entries), <code>0</code>(along row), <code>1</code>(along column)</p>
<p><code>np.var(x, ddof=0)</code>, <code>np.std(x, ddof=0)</code>, # Note both <code>np.var</code> and <code>np.std</code> accepts an argument <code>ddof</code>, the divisor is <code>N-ddof</code>.</p>
<p><code>np.linspace(-np.pi, np.pi, 50)</code> # start, end, number of points 50</p>
<p><code>np.multiply.outer(row,col)</code> # calculate the product over the mesh with vectors <code>row</code> and <code>col</code>.</p>
<p><code>np.zeros(shape or int, dtype)</code> #eg: <code>np.zeros(5,bool)</code></p>
<p><code>np.ones(Boston.shape[0])</code></p>
<p><code>np.all(x)</code>, <code>np.any(x)</code>: check if all or any entry of <code>x</code> is true.</p>
<p><code>np.unique(x)</code>: find unique values in <code>x</code>. <code>np.isnan(x)</code>: return a boolean array of <code>len(x)</code>. <code>np.isnan(x).mean()</code>: find the percentage of <code>np.nan</code> values in <code>x</code>.</p>
</section>
<section id="array-slicing-and-indexing" class="level4">
<h4 class="anchored" data-anchor-id="array-slicing-and-indexing">Array Slicing and indexing</h4>
<p><code>np.arange</code>(start, stop, step)<code># numpy version of</code>range`</p>
<p><code>x[slice(3:6)]</code> # equivalent to <code>x[3:6]</code></p>
<p>Using <code>[row, col]</code> format. If <code>col</code> is missing, then index the entire rows. <code>len(row)</code> must be equal to <code>len(col)</code>. Otherwise use iterative indexing or use <code>np.ix_(x_idx, y_idx)</code> function, or use Boolean indexing, see below.</p>
<pre><code>A[1,2]: index entry at row 1 and col 2 (recall Python index start from 0)
A[[1,3]] # row 1 and 3. Note the outer [] is considered as the operator, so only row indices are provided. 
A[:,[0,2]] # cols 0 and 2
A[[1,3], [0,2]] # entry A[1,0] and A[3,2]
A[1:4:2, 0:3:2] # entries in rows 1 and 3, cols 0 and 2
A[[1,3], [0,2,3]] # syntax error
# instead one can use the following two methods 
A[[1,3]][:,[0,2]] # iterative subsetting
A[np.ix_([1,3],[0,2,3])] # use .ix_ function to create an index mesh
A[keep_rows, keep_cols] # keep_rows, keep_cols are boolean arrays of the same length of rows or cols, respectively
A[np.ix_([1,3],keep_cols)] # np.ix_()can be applied to mixture of integer array and boolean array</code></pre>
</section>
<section id="random-numbers-and-generators" class="level4">
<h4 class="anchored" data-anchor-id="random-numbers-and-generators">Random numbers and generators</h4>
<pre><code>np.random.normal(loc=0.0, scale=1.0,size=None) # size can be an integer or a tuple.
# 
rng = np.random.default_rng(1303) # set random generator seed
rng.normal(loc=0, scale=5, size=2) # 
rng.standard_normal(10) # standard normal distribution of size 10
rng.choice([0, np.nan], p=[0.8,0.2], size=A.shape)</code></pre>
</section>
<section id="numpy-array-atributes" class="level4">
<h4 class="anchored" data-anchor-id="numpy-array-atributes">Numpy array atributes</h4>
<p><code>.dtype</code>, <code>.ndim</code>, <code>.shape</code></p>
</section>
<section id="numpy-array-methods" class="level4">
<h4 class="anchored" data-anchor-id="numpy-array-methods">Numpy array methods</h4>
<p><code>x.sum(axis=None)</code> (equivalent to <code>np.sum(x)</code>), <code>x.T</code> (transpose),</p>
<p><code>x.reshape((2,3))</code> # x.reshape() is a reference to x.</p>
<p><code>x.min()</code>, <code>x.max()</code></p>
</section>
</section>
<section id="graphics" class="level3">
<h3 class="anchored" data-anchor-id="graphics">Graphics</h3>
<section id="d-figure" class="level4">
<h4 class="anchored" data-anchor-id="d-figure">2-D figure</h4>
<pre><code># Using the subplots + ax methods
fig, ax = subplots(nrows=2, ncols=3, figsize=(8, 8)) 
ax[0,1].plot(x, y,marker='o', 'r--', linewidth=3); #line plot. `;` suppresses the text output. pick ax[0,1] when there are  multiple axes
ax.scatter(x, y, marker='o'); #scatter plot
ax.set_xlabel("this is the x-axis")
ax.set_ylabel("this is the y-axis")
ax.set_title("Plot of X vs Y");
axes[0,1].set_xlim([-1,1]) # set x_lim. similarly `set_ylim()`

fig = ax.figure  # get the figure object from an axes object
fig.set_size_inches(12,3) # access the fig object to change fig size
fig # re-render the figure
fig.savefig("Figure.pdf", dpi=200); #save a figure into pdf. Other formats: .jpg, .png, etc</code></pre>
</section>
<section id="contour-and-image" class="level4">
<h4 class="anchored" data-anchor-id="contour-and-image">Contour and image</h4>
<pre><code>fig, ax = subplots(figsize=(8, 8))
x = np.linspace(-np.pi, np.pi, 50)
y = x
f = np.multiply.outer(np.cos(y), 1 / (1 + x**2))
ax.contour(x, y, f, levels=None); # numbre of levels. if None, automatically choose
ax.imshow(f); # heatmap colorcoded by f</code></pre>
</section>
</section>
<section id="pandas" class="level3">
<h3 class="anchored" data-anchor-id="pandas">Pandas</h3>
<section id="loading-data" class="level4">
<h4 class="anchored" data-anchor-id="loading-data">loading data</h4>
<pre><code>pd.read_csv('Auto.csv') # read csv
pd.read_csv('Auto.data', 
            na_values =['?'], #specifying the na_values in the datafile. 
            delim_whitespace=True) # read whitespaced text file
pd.read_csv('College.csv', index_col=0) # use column `0` as teh row labels 
</code></pre>
</section>
<section id="pandas-dataframe-attributes-and-methods" class="level4">
<h4 class="anchored" data-anchor-id="pandas-dataframe-attributes-and-methods">Pandas Dataframe attributes and methods</h4>
<pre><code>Auto.shape
Auto.columns # gets the list of column names
Auto.index #return the index (labels) objects
Auto['horsepower'].to_numpy() # convert to numpy array
Auto['horsepower'].sum()
Auto.dropna() # drop the rows containing na values. 
Auto.set_index('name')# rename the index using the column 'name'.

pd.Series(Auto.cylinders, dtype='category') # convert the column `cylinders` to 'category` dtype
# the convertison can be done using `astype()` method
Auto.cylinders.astype('category')
Auto.describe() # statistics summary of all columns
Auto['mpg'].describe() # for selected columns
college.rename({'Unnamed: 0': 'College'}, axis=1): # change column name
college['Elite'] = pd.cut(college['Top10perc'],  # binning a column
                          [0,0.5,1],  #bin edges
                          labels=['No', 'Yes']
                          right=True,# True: right-inclusive for each bin ( ]; False:rigth-exclusive 
                          )   # bin labels (names)
college['Elite'].value_counts() # frequency counts
</code></pre>
</section>
<section id="selecting-rows-and-columns" class="level4">
<h4 class="anchored" data-anchor-id="selecting-rows-and-columns">Selecting rows and columns</h4>
<p>Select Rows:</p>
<pre><code>Auto[:3] # the first 3 rows. 
Auto[Auto['year'] &gt; 80] # select rows with boolean array
Auto_re.loc[['amc rebel sst', 'ford torino']] #label_based row selection
Auto_re.iloc[[3,4]] #integer-based row seleciton: rows 3 and 4 (index starting from 0)</code></pre>
<p>Select Columns</p>
<pre><code>Auto['horsepower'] # select the column 'horsepower', resulting a pd.Series.
Auto[['horsepower']] #obtain a dataframe of the column 'horsepower'. 
Auto_re.iloc[:,[0,2,3]] # intger-based selection</code></pre>
<p>Select a subset</p>
<pre><code>Auto_re.iloc[[3,4],[0,2,3]] # integer-basd 
Auto_re.loc['ford galaxie 500', ['mpg', 'origin']] #label-based 
Auto_re.loc[Auto_re['year'] &gt; 80, ['weight', 'origin']] # mix bolean indexing with labels

Auto_re.loc[lambda df: (df['year'] &gt; 80) &amp; (df['mpg'] &gt; 30),
            ['weight', 'origin']
           ]  # using labmda function with loc[]</code></pre>
</section>
<section id="pandas-graphics" class="level4">
<h4 class="anchored" data-anchor-id="pandas-graphics">Pandas graphics</h4>
<p>Without using <code>subplots</code> to get axes and figure objects</p>
<pre><code>ax = Auto.plot.scatter('horsepower', 'mpg') #scatter plot of 'horsepower' vs 'mpg' from the dataframe Auto
ax.set_title('Horsepower vs. MPG');
fig = ax.figure
fig.savefig('horsepower_mpg.png');
</code></pre>
<p>Using <code>subplots</code></p>
<pre><code>fig, axes = subplots(  ncols=3, figsize=(15, 5))
Auto.plot.scatter('horsepower', 'mpg', ax=axes[1]);
Auto.hist('mpg', ax=ax);
Auto.hist('mpg', color='red', bins=12, ax=ax); # more customized </code></pre>
<p>Boxplot using <code>subplots</code></p>
<pre><code>Auto.cylinders = pd.Series(Auto.cylinders, dtype='category') # needs to convert the `cylinders` column to categorical dtype
fig, ax = subplots(figsize=(8, 8))
Auto.boxplot('mpg', by='cylinders', ax=ax);</code></pre>
<p>Scatter matrix</p>
<pre><code>pd.plotting.scatter_matrix(Auto); # all columns
pd.plotting.scatter_matrix(Auto[['mpg',
                                 'displacement',
                                 'weight']]);  # selected columns</code></pre>
</section>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>